{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWZ5WpWmhAE9"
      },
      "source": [
        "# Training using Stable Baselines for Shimmy DM Control"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IowaxgFOhENG",
        "outputId": "303a0aee-76ac-4791-c1ba-7a51393366a7"
      },
      "outputs": [],
      "source": [
        "!apt-get install -y \\\n",
        "    libgl1-mesa-dev \\\n",
        "    libgl1-mesa-glx \\\n",
        "    libglew-dev \\\n",
        "    libosmesa6-dev \\\n",
        "    software-properties-common\n",
        "\n",
        "!apt-get install -y patchelf\n",
        "\n",
        "!apt-get install -y libx11-dev\n",
        "!apt-get install -y build-essential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPESKp3chNnF",
        "outputId": "0c4bf3a5-b012-4bb1-8c17-67f50987d7e7"
      },
      "outputs": [],
      "source": [
        "%pip install gymnasium\n",
        "%pip install shimmy[dm-control]\n",
        "%pip install comet_ml\n",
        "%pip install free-mujoco-py\n",
        "%pip install stable-baselines3[extra]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiPrsLZShX3t",
        "outputId": "d6243f84-df22-45c7-e829-1656409a14a9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/landolt/DeepRL/.venv/lib/python3.10/site-packages/Cython/Distutils/old_build_ext.py:15: DeprecationWarning: dep_util is Deprecated. Use functions from setuptools instead.\n",
            "  from distutils.dep_util import newer, newer_group\n",
            "/home/landolt/DeepRL/.venv/lib/python3.10/site-packages/Cython/Distutils/old_build_ext.py:15: DeprecationWarning: dep_util is Deprecated. Use functions from setuptools instead.\n",
            "  from distutils.dep_util import newer, newer_group\n",
            "<frozen importlib._bootstrap>:283: DeprecationWarning: the load_module() method is deprecated and slated for removal in Python 3.12; use exec_module() instead\n",
            "/home/landolt/DeepRL/.venv/lib/python3.10/site-packages/pygame/pkgdata.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
            "  from pkg_resources import resource_stream, resource_exists\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pygame 2.5.2 (SDL 2.28.2, Python 3.10.12)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.distributions.normal import Normal\n",
        "\n",
        "import gymnasium as gym\n",
        "\n",
        "from comet_ml import Experiment\n",
        "from comet_ml.integration.gymnasium import CometLogger\n",
        "\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (10, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "total_timesteps = 10000000\n",
        "n_steps = 5000\n",
        "learning_rate = 0.02\n",
        "batch_size = 512\n",
        "gamma = 0.99"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bp_LdiqphilV",
        "outputId": "c6f5f1b6-3620-42a3-c841-072b3ab7b9fb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/clandolt/deeprl/dda87f3b617b4330917116315dace27c\n",
            "\n",
            "/home/landolt/DeepRL/.venv/lib/python3.10/site-packages/gymnasium/wrappers/record_video.py:94: UserWarning: \u001b[33mWARN: Overwriting existing videos at /home/landolt/DeepRL/test folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/landolt/DeepRL/.venv/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 256, but because the `RolloutBuffer` is of size `n_steps * n_envs = 4000`, after every 15 untruncated mini-batches, there will be a truncated mini-batch of size 160\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=4000 and n_envs=1)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moviepy - Building video /home/landolt/DeepRL/test/rl-video-episode-0.mp4.\n",
            "Moviepy - Writing video /home/landolt/DeepRL/test/rl-video-episode-0.mp4\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /home/landolt/DeepRL/test/rl-video-episode-0.mp4\n",
            "Moviepy - Building video /home/landolt/DeepRL/test/rl-video-episode-1.mp4.\n",
            "Moviepy - Writing video /home/landolt/DeepRL/test/rl-video-episode-1.mp4\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /home/landolt/DeepRL/test/rl-video-episode-1.mp4\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 3.63e+04 |\n",
            "| time/              |          |\n",
            "|    fps             | 307      |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 13       |\n",
            "|    total_timesteps | 4000     |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 3.79e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 458         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 17          |\n",
            "|    total_timesteps      | 8000        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024064675 |\n",
            "|    clip_fraction        | 0.281       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -24.1       |\n",
            "|    explained_variance   | -0.000544   |\n",
            "|    learning_rate        | 0.002       |\n",
            "|    loss                 | 1.63e+05    |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0545     |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 3.52e+05    |\n",
            "-----------------------------------------\n",
            "Moviepy - Building video /home/landolt/DeepRL/test/rl-video-episode-8.mp4.\n",
            "Moviepy - Writing video /home/landolt/DeepRL/test/rl-video-episode-8.mp4\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /home/landolt/DeepRL/test/rl-video-episode-8.mp4\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 3.84e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 459         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 26          |\n",
            "|    total_timesteps      | 12000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019676127 |\n",
            "|    clip_fraction        | 0.197       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -24.1       |\n",
            "|    explained_variance   | -0.0063     |\n",
            "|    learning_rate        | 0.002       |\n",
            "|    loss                 | 2e+05       |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0546     |\n",
            "|    std                  | 0.999       |\n",
            "|    value_loss           | 4.28e+05    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1e+03      |\n",
            "|    ep_rew_mean          | 3.95e+04   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 525        |\n",
            "|    iterations           | 4          |\n",
            "|    time_elapsed         | 30         |\n",
            "|    total_timesteps      | 16000      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02424644 |\n",
            "|    clip_fraction        | 0.259      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -24.1      |\n",
            "|    explained_variance   | -0.000107  |\n",
            "|    learning_rate        | 0.002      |\n",
            "|    loss                 | 1.92e+05   |\n",
            "|    n_updates            | 30         |\n",
            "|    policy_gradient_loss | -0.0583    |\n",
            "|    std                  | 0.997      |\n",
            "|    value_loss           | 4.12e+05   |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1e+03      |\n",
            "|    ep_rew_mean          | 3.96e+04   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 575        |\n",
            "|    iterations           | 5          |\n",
            "|    time_elapsed         | 34         |\n",
            "|    total_timesteps      | 20000      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02388521 |\n",
            "|    clip_fraction        | 0.242      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -24.1      |\n",
            "|    explained_variance   | -0.00593   |\n",
            "|    learning_rate        | 0.002      |\n",
            "|    loss                 | 2.68e+05   |\n",
            "|    n_updates            | 40         |\n",
            "|    policy_gradient_loss | -0.0581    |\n",
            "|    std                  | 0.995      |\n",
            "|    value_loss           | 4.98e+05   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 4.01e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 613         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 39          |\n",
            "|    total_timesteps      | 24000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.027173959 |\n",
            "|    clip_fraction        | 0.289       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -24         |\n",
            "|    explained_variance   | -0.00716    |\n",
            "|    learning_rate        | 0.002       |\n",
            "|    loss                 | 2.06e+05    |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.0652     |\n",
            "|    std                  | 0.994       |\n",
            "|    value_loss           | 4.28e+05    |\n",
            "-----------------------------------------\n",
            "Moviepy - Building video /home/landolt/DeepRL/test/rl-video-episode-27.mp4.\n",
            "Moviepy - Writing video /home/landolt/DeepRL/test/rl-video-episode-27.mp4\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /home/landolt/DeepRL/test/rl-video-episode-27.mp4\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1e+03      |\n",
            "|    ep_rew_mean          | 4.05e+04   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 584        |\n",
            "|    iterations           | 7          |\n",
            "|    time_elapsed         | 47         |\n",
            "|    total_timesteps      | 28000      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02964586 |\n",
            "|    clip_fraction        | 0.306      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -24        |\n",
            "|    explained_variance   | -0.00261   |\n",
            "|    learning_rate        | 0.002      |\n",
            "|    loss                 | 2.07e+05   |\n",
            "|    n_updates            | 60         |\n",
            "|    policy_gradient_loss | -0.0717    |\n",
            "|    std                  | 0.991      |\n",
            "|    value_loss           | 4.65e+05   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 4.09e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 612         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 52          |\n",
            "|    total_timesteps      | 32000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.031649884 |\n",
            "|    clip_fraction        | 0.306       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -23.9       |\n",
            "|    explained_variance   | -0.00246    |\n",
            "|    learning_rate        | 0.002       |\n",
            "|    loss                 | 2.25e+05    |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.0671     |\n",
            "|    std                  | 0.989       |\n",
            "|    value_loss           | 4.86e+05    |\n",
            "-----------------------------------------\n",
            "--------------------------------------\n",
            "| rollout/                |          |\n",
            "|    ep_len_mean          | 1e+03    |\n",
            "|    ep_rew_mean          | 4.14e+04 |\n",
            "| time/                   |          |\n",
            "|    fps                  | 636      |\n",
            "|    iterations           | 9        |\n",
            "|    time_elapsed         | 56       |\n",
            "|    total_timesteps      | 36000    |\n",
            "| train/                  |          |\n",
            "|    approx_kl            | 0.032866 |\n",
            "|    clip_fraction        | 0.339    |\n",
            "|    clip_range           | 0.2      |\n",
            "|    entropy_loss         | -23.9    |\n",
            "|    explained_variance   | 8.26e-05 |\n",
            "|    learning_rate        | 0.002    |\n",
            "|    loss                 | 2.42e+05 |\n",
            "|    n_updates            | 80       |\n",
            "|    policy_gradient_loss | -0.0669  |\n",
            "|    std                  | 0.988    |\n",
            "|    value_loss           | 4.9e+05  |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 4.19e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 657         |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 60          |\n",
            "|    total_timesteps      | 40000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.035950806 |\n",
            "|    clip_fraction        | 0.319       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -23.9       |\n",
            "|    explained_variance   | -0.0108     |\n",
            "|    learning_rate        | 0.002       |\n",
            "|    loss                 | 2.58e+05    |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.0632     |\n",
            "|    std                  | 0.985       |\n",
            "|    value_loss           | 5.36e+05    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1e+03      |\n",
            "|    ep_rew_mean          | 4.25e+04   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 674        |\n",
            "|    iterations           | 11         |\n",
            "|    time_elapsed         | 65         |\n",
            "|    total_timesteps      | 44000      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.03795045 |\n",
            "|    clip_fraction        | 0.342      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -23.8      |\n",
            "|    explained_variance   | -0.00316   |\n",
            "|    learning_rate        | 0.002      |\n",
            "|    loss                 | 2.73e+05   |\n",
            "|    n_updates            | 100        |\n",
            "|    policy_gradient_loss | -0.0678    |\n",
            "|    std                  | 0.984      |\n",
            "|    value_loss           | 5.51e+05   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 4.3e+04     |\n",
            "| time/                   |             |\n",
            "|    fps                  | 690         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 69          |\n",
            "|    total_timesteps      | 48000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.042858288 |\n",
            "|    clip_fraction        | 0.361       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -23.8       |\n",
            "|    explained_variance   | 0.000106    |\n",
            "|    learning_rate        | 0.002       |\n",
            "|    loss                 | 3.16e+05    |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.0684     |\n",
            "|    std                  | 0.983       |\n",
            "|    value_loss           | 6.15e+05    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1e+03      |\n",
            "|    ep_rew_mean          | 4.38e+04   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 704        |\n",
            "|    iterations           | 13         |\n",
            "|    time_elapsed         | 73         |\n",
            "|    total_timesteps      | 52000      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.04070298 |\n",
            "|    clip_fraction        | 0.352      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -23.8      |\n",
            "|    explained_variance   | -0.000152  |\n",
            "|    learning_rate        | 0.002      |\n",
            "|    loss                 | 2.67e+05   |\n",
            "|    n_updates            | 120        |\n",
            "|    policy_gradient_loss | -0.0686    |\n",
            "|    std                  | 0.981      |\n",
            "|    value_loss           | 6.09e+05   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 4.45e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 717         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 78          |\n",
            "|    total_timesteps      | 56000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.040154897 |\n",
            "|    clip_fraction        | 0.354       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -23.8       |\n",
            "|    explained_variance   | -0.0126     |\n",
            "|    learning_rate        | 0.002       |\n",
            "|    loss                 | 3.38e+05    |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.0664     |\n",
            "|    std                  | 0.98        |\n",
            "|    value_loss           | 7.28e+05    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1e+03      |\n",
            "|    ep_rew_mean          | 4.53e+04   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 727        |\n",
            "|    iterations           | 15         |\n",
            "|    time_elapsed         | 82         |\n",
            "|    total_timesteps      | 60000      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.04148982 |\n",
            "|    clip_fraction        | 0.347      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -23.7      |\n",
            "|    explained_variance   | -0.00248   |\n",
            "|    learning_rate        | 0.002      |\n",
            "|    loss                 | 3.93e+05   |\n",
            "|    n_updates            | 140        |\n",
            "|    policy_gradient_loss | -0.064     |\n",
            "|    std                  | 0.977      |\n",
            "|    value_loss           | 7.68e+05   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 4.62e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 737         |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 86          |\n",
            "|    total_timesteps      | 64000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.046020944 |\n",
            "|    clip_fraction        | 0.377       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -23.7       |\n",
            "|    explained_variance   | 3.35e-05    |\n",
            "|    learning_rate        | 0.002       |\n",
            "|    loss                 | 4.57e+05    |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.0671     |\n",
            "|    std                  | 0.973       |\n",
            "|    value_loss           | 8.77e+05    |\n",
            "-----------------------------------------\n",
            "Moviepy - Building video /home/landolt/DeepRL/test/rl-video-episode-64.mp4.\n",
            "Moviepy - Writing video /home/landolt/DeepRL/test/rl-video-episode-64.mp4\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /home/landolt/DeepRL/test/rl-video-episode-64.mp4\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 4.7e+04     |\n",
            "| time/                   |             |\n",
            "|    fps                  | 710         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 95          |\n",
            "|    total_timesteps      | 68000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.044175055 |\n",
            "|    clip_fraction        | 0.373       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -23.6       |\n",
            "|    explained_variance   | -8.39e-05   |\n",
            "|    learning_rate        | 0.002       |\n",
            "|    loss                 | 4.29e+05    |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -0.0681     |\n",
            "|    std                  | 0.968       |\n",
            "|    value_loss           | 9.21e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 4.78e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 720         |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 99          |\n",
            "|    total_timesteps      | 72000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.045867827 |\n",
            "|    clip_fraction        | 0.37        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -23.5       |\n",
            "|    explained_variance   | 1.39e-05    |\n",
            "|    learning_rate        | 0.002       |\n",
            "|    loss                 | 4.5e+05     |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.0703     |\n",
            "|    std                  | 0.965       |\n",
            "|    value_loss           | 9.25e+05    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1e+03      |\n",
            "|    ep_rew_mean          | 4.87e+04   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 729        |\n",
            "|    iterations           | 19         |\n",
            "|    time_elapsed         | 104        |\n",
            "|    total_timesteps      | 76000      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.04606635 |\n",
            "|    clip_fraction        | 0.37       |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -23.5      |\n",
            "|    explained_variance   | 0.000774   |\n",
            "|    learning_rate        | 0.002      |\n",
            "|    loss                 | 4.71e+05   |\n",
            "|    n_updates            | 180        |\n",
            "|    policy_gradient_loss | -0.0741    |\n",
            "|    std                  | 0.962      |\n",
            "|    value_loss           | 9.93e+05   |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1e+03      |\n",
            "|    ep_rew_mean          | 4.96e+04   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 736        |\n",
            "|    iterations           | 20         |\n",
            "|    time_elapsed         | 108        |\n",
            "|    total_timesteps      | 80000      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.04684174 |\n",
            "|    clip_fraction        | 0.371      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -23.4      |\n",
            "|    explained_variance   | 0.00107    |\n",
            "|    learning_rate        | 0.002      |\n",
            "|    loss                 | 4.75e+05   |\n",
            "|    n_updates            | 190        |\n",
            "|    policy_gradient_loss | -0.0732    |\n",
            "|    std                  | 0.96       |\n",
            "|    value_loss           | 1.09e+06   |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 1e+03     |\n",
            "|    ep_rew_mean          | 5.05e+04  |\n",
            "| time/                   |           |\n",
            "|    fps                  | 743       |\n",
            "|    iterations           | 21        |\n",
            "|    time_elapsed         | 112       |\n",
            "|    total_timesteps      | 84000     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0518929 |\n",
            "|    clip_fraction        | 0.402     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -23.4     |\n",
            "|    explained_variance   | -0.000163 |\n",
            "|    learning_rate        | 0.002     |\n",
            "|    loss                 | 5.51e+05  |\n",
            "|    n_updates            | 200       |\n",
            "|    policy_gradient_loss | -0.0724   |\n",
            "|    std                  | 0.958     |\n",
            "|    value_loss           | 1.16e+06  |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1e+03      |\n",
            "|    ep_rew_mean          | 5.11e+04   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 751        |\n",
            "|    iterations           | 22         |\n",
            "|    time_elapsed         | 117        |\n",
            "|    total_timesteps      | 88000      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.05009449 |\n",
            "|    clip_fraction        | 0.403      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -23.3      |\n",
            "|    explained_variance   | 0.000294   |\n",
            "|    learning_rate        | 0.002      |\n",
            "|    loss                 | 7e+05      |\n",
            "|    n_updates            | 210        |\n",
            "|    policy_gradient_loss | -0.0774    |\n",
            "|    std                  | 0.955      |\n",
            "|    value_loss           | 1.26e+06   |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1e+03      |\n",
            "|    ep_rew_mean          | 5.15e+04   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 757        |\n",
            "|    iterations           | 23         |\n",
            "|    time_elapsed         | 121        |\n",
            "|    total_timesteps      | 92000      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.05398217 |\n",
            "|    clip_fraction        | 0.408      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -23.3      |\n",
            "|    explained_variance   | -0.000596  |\n",
            "|    learning_rate        | 0.002      |\n",
            "|    loss                 | 5.27e+05   |\n",
            "|    n_updates            | 220        |\n",
            "|    policy_gradient_loss | -0.0724    |\n",
            "|    std                  | 0.955      |\n",
            "|    value_loss           | 1.05e+06   |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 1e+03     |\n",
            "|    ep_rew_mean          | 5.2e+04   |\n",
            "| time/                   |           |\n",
            "|    fps                  | 763       |\n",
            "|    iterations           | 24        |\n",
            "|    time_elapsed         | 125       |\n",
            "|    total_timesteps      | 96000     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0651806 |\n",
            "|    clip_fraction        | 0.442     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -23.3     |\n",
            "|    explained_variance   | -0.000563 |\n",
            "|    learning_rate        | 0.002     |\n",
            "|    loss                 | 4.52e+05  |\n",
            "|    n_updates            | 230       |\n",
            "|    policy_gradient_loss | -0.0717   |\n",
            "|    std                  | 0.955     |\n",
            "|    value_loss           | 9.27e+05  |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 5.28e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 767         |\n",
            "|    iterations           | 25          |\n",
            "|    time_elapsed         | 130         |\n",
            "|    total_timesteps      | 100000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.063048296 |\n",
            "|    clip_fraction        | 0.439       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -23.3       |\n",
            "|    explained_variance   | -0.000275   |\n",
            "|    learning_rate        | 0.002       |\n",
            "|    loss                 | 4.7e+05     |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | -0.0727     |\n",
            "|    std                  | 0.953       |\n",
            "|    value_loss           | 1.02e+06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 5.39e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 772         |\n",
            "|    iterations           | 26          |\n",
            "|    time_elapsed         | 134         |\n",
            "|    total_timesteps      | 104000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.055641662 |\n",
            "|    clip_fraction        | 0.398       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -23.2       |\n",
            "|    explained_variance   | -0.000339   |\n",
            "|    learning_rate        | 0.002       |\n",
            "|    loss                 | 7.23e+05    |\n",
            "|    n_updates            | 250         |\n",
            "|    policy_gradient_loss | -0.0747     |\n",
            "|    std                  | 0.948       |\n",
            "|    value_loss           | 1.42e+06    |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 1e+03     |\n",
            "|    ep_rew_mean          | 5.51e+04  |\n",
            "| time/                   |           |\n",
            "|    fps                  | 777       |\n",
            "|    iterations           | 27        |\n",
            "|    time_elapsed         | 138       |\n",
            "|    total_timesteps      | 108000    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0648713 |\n",
            "|    clip_fraction        | 0.441     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -23.2     |\n",
            "|    explained_variance   | -0.00311  |\n",
            "|    learning_rate        | 0.002     |\n",
            "|    loss                 | 4.59e+05  |\n",
            "|    n_updates            | 260       |\n",
            "|    policy_gradient_loss | -0.0703   |\n",
            "|    std                  | 0.947     |\n",
            "|    value_loss           | 9.88e+05  |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1e+03      |\n",
            "|    ep_rew_mean          | 5.62e+04   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 781        |\n",
            "|    iterations           | 28         |\n",
            "|    time_elapsed         | 143        |\n",
            "|    total_timesteps      | 112000     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.06470339 |\n",
            "|    clip_fraction        | 0.417      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -23.2      |\n",
            "|    explained_variance   | -0.00314   |\n",
            "|    learning_rate        | 0.002      |\n",
            "|    loss                 | 5.78e+05   |\n",
            "|    n_updates            | 270        |\n",
            "|    policy_gradient_loss | -0.0698    |\n",
            "|    std                  | 0.948      |\n",
            "|    value_loss           | 1.18e+06   |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1e+03      |\n",
            "|    ep_rew_mean          | 5.72e+04   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 784        |\n",
            "|    iterations           | 29         |\n",
            "|    time_elapsed         | 147        |\n",
            "|    total_timesteps      | 116000     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.07451012 |\n",
            "|    clip_fraction        | 0.442      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -23.2      |\n",
            "|    explained_variance   | -0.0021    |\n",
            "|    learning_rate        | 0.002      |\n",
            "|    loss                 | 5.88e+05   |\n",
            "|    n_updates            | 280        |\n",
            "|    policy_gradient_loss | -0.0736    |\n",
            "|    std                  | 0.947      |\n",
            "|    value_loss           | 1.2e+06    |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 1e+03     |\n",
            "|    ep_rew_mean          | 5.85e+04  |\n",
            "| time/                   |           |\n",
            "|    fps                  | 788       |\n",
            "|    iterations           | 30        |\n",
            "|    time_elapsed         | 152       |\n",
            "|    total_timesteps      | 120000    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0728627 |\n",
            "|    clip_fraction        | 0.446     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -23.2     |\n",
            "|    explained_variance   | 7.79e-05  |\n",
            "|    learning_rate        | 0.002     |\n",
            "|    loss                 | 5.57e+05  |\n",
            "|    n_updates            | 290       |\n",
            "|    policy_gradient_loss | -0.0744   |\n",
            "|    std                  | 0.944     |\n",
            "|    value_loss           | 1.13e+06  |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1e+03      |\n",
            "|    ep_rew_mean          | 5.97e+04   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 792        |\n",
            "|    iterations           | 31         |\n",
            "|    time_elapsed         | 156        |\n",
            "|    total_timesteps      | 124000     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.06526529 |\n",
            "|    clip_fraction        | 0.44       |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -23.1      |\n",
            "|    explained_variance   | 0.000319   |\n",
            "|    learning_rate        | 0.002      |\n",
            "|    loss                 | 7.08e+05   |\n",
            "|    n_updates            | 300        |\n",
            "|    policy_gradient_loss | -0.0746    |\n",
            "|    std                  | 0.944      |\n",
            "|    value_loss           | 1.4e+06    |\n",
            "----------------------------------------\n",
            "Moviepy - Building video /home/landolt/DeepRL/test/rl-video-episode-125.mp4.\n",
            "Moviepy - Writing video /home/landolt/DeepRL/test/rl-video-episode-125.mp4\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /home/landolt/DeepRL/test/rl-video-episode-125.mp4\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1e+03      |\n",
            "|    ep_rew_mean          | 6.09e+04   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 774        |\n",
            "|    iterations           | 32         |\n",
            "|    time_elapsed         | 165        |\n",
            "|    total_timesteps      | 128000     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.07193029 |\n",
            "|    clip_fraction        | 0.443      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -23.1      |\n",
            "|    explained_variance   | 0.000191   |\n",
            "|    learning_rate        | 0.002      |\n",
            "|    loss                 | 7e+05      |\n",
            "|    n_updates            | 310        |\n",
            "|    policy_gradient_loss | -0.0717    |\n",
            "|    std                  | 0.944      |\n",
            "|    value_loss           | 1.3e+06    |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | 6.2e+04     |\n",
            "| time/                   |             |\n",
            "|    fps                  | 778         |\n",
            "|    iterations           | 33          |\n",
            "|    time_elapsed         | 169         |\n",
            "|    total_timesteps      | 132000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.069590926 |\n",
            "|    clip_fraction        | 0.427       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -23.1       |\n",
            "|    explained_variance   | -0.000135   |\n",
            "|    learning_rate        | 0.002       |\n",
            "|    loss                 | 6.94e+05    |\n",
            "|    n_updates            | 320         |\n",
            "|    policy_gradient_loss | -0.0709     |\n",
            "|    std                  | 0.943       |\n",
            "|    value_loss           | 1.38e+06    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1e+03      |\n",
            "|    ep_rew_mean          | 6.32e+04   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 782        |\n",
            "|    iterations           | 34         |\n",
            "|    time_elapsed         | 173        |\n",
            "|    total_timesteps      | 136000     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.07805602 |\n",
            "|    clip_fraction        | 0.469      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -23.1      |\n",
            "|    explained_variance   | 6.08e-06   |\n",
            "|    learning_rate        | 0.002      |\n",
            "|    loss                 | 6.21e+05   |\n",
            "|    n_updates            | 330        |\n",
            "|    policy_gradient_loss | -0.0764    |\n",
            "|    std                  | 0.94       |\n",
            "|    value_loss           | 1.24e+06   |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1e+03      |\n",
            "|    ep_rew_mean          | 6.42e+04   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 785        |\n",
            "|    iterations           | 35         |\n",
            "|    time_elapsed         | 178        |\n",
            "|    total_timesteps      | 140000     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.07625049 |\n",
            "|    clip_fraction        | 0.456      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -23        |\n",
            "|    explained_variance   | 2.55e-05   |\n",
            "|    learning_rate        | 0.002      |\n",
            "|    loss                 | 6.8e+05    |\n",
            "|    n_updates            | 340        |\n",
            "|    policy_gradient_loss | -0.0736    |\n",
            "|    std                  | 0.937      |\n",
            "|    value_loss           | 1.36e+06   |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1e+03      |\n",
            "|    ep_rew_mean          | 6.53e+04   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 788        |\n",
            "|    iterations           | 36         |\n",
            "|    time_elapsed         | 182        |\n",
            "|    total_timesteps      | 144000     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.07637018 |\n",
            "|    clip_fraction        | 0.448      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -23        |\n",
            "|    explained_variance   | 0.00018    |\n",
            "|    learning_rate        | 0.002      |\n",
            "|    loss                 | 6.04e+05   |\n",
            "|    n_updates            | 350        |\n",
            "|    policy_gradient_loss | -0.0685    |\n",
            "|    std                  | 0.935      |\n",
            "|    value_loss           | 1.29e+06   |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1e+03      |\n",
            "|    ep_rew_mean          | 6.65e+04   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 790        |\n",
            "|    iterations           | 37         |\n",
            "|    time_elapsed         | 187        |\n",
            "|    total_timesteps      | 148000     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.07720393 |\n",
            "|    clip_fraction        | 0.462      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -22.9      |\n",
            "|    explained_variance   | 0.000409   |\n",
            "|    learning_rate        | 0.002      |\n",
            "|    loss                 | 6.95e+05   |\n",
            "|    n_updates            | 360        |\n",
            "|    policy_gradient_loss | -0.0766    |\n",
            "|    std                  | 0.932      |\n",
            "|    value_loss           | 1.43e+06   |\n",
            "----------------------------------------\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m action_noise \u001b[38;5;241m=\u001b[39m NormalActionNoise(mean\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mzeros(n_actions), sigma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mones(n_actions))\n\u001b[1;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m PPO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m, env, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, n_steps\u001b[38;5;241m=\u001b[39mn_steps, learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, gamma\u001b[38;5;241m=\u001b[39mgamma)\n\u001b[0;32m---> 18\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Save the agent\u001b[39;00m\n\u001b[1;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mppo_humanoid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/DeepRL/.venv/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py:315\u001b[0m, in \u001b[0;36mPPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[1;32m    308\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    313\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    314\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[0;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/DeepRL/.venv/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:313\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mep_info_buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    311\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dump_logs(iteration)\n\u001b[0;32m--> 313\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_end()\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "File \u001b[0;32m~/DeepRL/.venv/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py:281\u001b[0m, in \u001b[0;36mPPO.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    279\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;66;03m# Clip grad norm\u001b[39;00m\n\u001b[0;32m--> 281\u001b[0m     \u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip_grad_norm_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_grad_norm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_updates \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "File \u001b[0;32m~/DeepRL/.venv/lib/python3.10/site-packages/torch/nn/utils/clip_grad.py:20\u001b[0m, in \u001b[0;36m_no_grad.<locals>._no_grad_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_no_grad_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 20\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/DeepRL/.venv/lib/python3.10/site-packages/torch/nn/utils/clip_grad.py:85\u001b[0m, in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[1;32m     81\u001b[0m clip_coef \u001b[38;5;241m=\u001b[39m max_norm \u001b[38;5;241m/\u001b[39m (total_norm \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-6\u001b[39m)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Note: multiplying by the clamped coef is redundant when the coef is clamped to 1, but doing so\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# avoids a `if clip_coef < 1:` conditional which can require a CPU <=> device synchronization\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# when the gradients do not reside in CPU memory.\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m clip_coef_clamped \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclamp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclip_coef\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ((device, _), ([device_grads], _)) \u001b[38;5;129;01min\u001b[39;00m grouped_grads\u001b[38;5;241m.\u001b[39mitems():  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m     88\u001b[0m         (foreach \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m _has_foreach_support(device_grads, device))\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (foreach \u001b[38;5;129;01mand\u001b[39;00m _device_has_foreach_support(device))\n\u001b[1;32m     90\u001b[0m     ):\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "experiment = Experiment(\n",
        "    api_key=\"eDVXm91zIoTyF8BUArQquxAmM\",\n",
        "    project_name=\"deeprl\",\n",
        "    workspace=\"clandolt\",\n",
        ")\n",
        "\n",
        "# Create and wrap the environment\n",
        "env = gym.make(\"HumanoidStandup-v4\", render_mode=\"rgb_array\")\n",
        "env = gym.wrappers.RecordVideo(env, 'test')\n",
        "env = CometLogger(env, experiment)\n",
        "observation, info = env.reset(seed=42)\n",
        "\n",
        "model = PPO(\"MlpPolicy\", env, verbose=1, n_steps=n_steps, learning_rate=learning_rate, batch_size=batch_size, gamma=gamma)\n",
        "model.learn(total_timesteps=total_timesteps, reset_num_timesteps=False)\n",
        "# Save the agent\n",
        "model.save(\"ppo_humanoid\")\n",
        "vec_env = model.get_env()\n",
        "\n",
        "del model  # delete trained model to demonstrate loading\n",
        "\n",
        "# Load the trained agent\n",
        "# NOTE: if you have loading issue, you can pass `print_system_info=True`\n",
        "# to compare the system on which the model was trained vs the current one\n",
        "# model = DQN.load(\"dqn_lunar\", env=env, print_system_info=True)\n",
        "model = PPO.load(\"ppo_humanoid\", env=env)\n",
        "\n",
        "# Evaluate the agent\n",
        "# NOTE: If you use wrappers with your environment that modify rewards,\n",
        "#       this will be reflected here. To evaluate with original rewards,\n",
        "#       wrap environment in a \"Monitor\" wrapper before other wrappers.\n",
        "mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=10)\n",
        "\n",
        "# Enjoy trained agent\n",
        "vec_env = model.get_env()\n",
        "obs = vec_env.reset()\n",
        "for i in range(100000):\n",
        "    action, _states = model.predict(obs, deterministic=True)\n",
        "    obs, rewards, dones, info = vec_env.step(action)\n",
        "    vec_env.render(\"human\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ikpa4s9antl2"
      },
      "outputs": [],
      "source": [
        "experiment.end()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PYIe1wsLkDa-"
      },
      "outputs": [],
      "source": [
        "experiment.display()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fOr0P1rMnkP9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
